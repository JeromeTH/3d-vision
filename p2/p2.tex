\documentclass{article}

% Packages for math and formatting
\usepackage{amsmath, amssymb}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{physics}


% Page setup
\geometry{margin=1in}

\begin{document}
Problem: 
Given an image
$(u, v) \in [0, W) \times [0, H)$  
sampled from $360$ view by 
$\lambda(u) = 2\pi \frac{u}{W} - \pi $
$\phi(v) = \frac{\pi}{2} - \pi\frac{v}{H} $

\section{Part 1}
General Strategy outline: 
\begin{itemize}
    \item First, we want to transform the image into pixel on the viewing sphere in 3D space obtaining $(\lambda_w, \phi_w)$. 
    \item Then, rotate the sphere to position relative to the camera, obtaining $(\lambda_c, \phi_c)$. 
    \item Sample (u', v') within latitude range and longtitude range $(\pi / 4, -\pi / 4)$ from $(\lambda_c, \phi_c)$.
\end{itemize}

\subsection{Transforming image into 3D Dome}
The affine transformation $\tau : (u, v) \rightarrow (\lambda_w, \phi_w)$ can be seen as linear transformation in homogenous $P^2$ space, 
denoted by matrix multiplication: 
\begin{align*}
    \begin{bmatrix}
    \frac{2\pi}{W} & 0 & -\pi \\
    0 & \frac{-\pi}{H} & \frac{\pi}{2} \\
    0 & 0 & 1
    \end{bmatrix}
    \begin{bmatrix}
        u \\ v \\ 1
    \end{bmatrix}
    = S \begin{bmatrix}
        u \\ v \\ 1
    \end{bmatrix} = 
    \begin{bmatrix}
        \lambda_w \\ \phi_w \\ 1
    \end{bmatrix} 
\end{align*}

Computing the inverse allows us to sample points on the 3D sphere using the information in the image by
$$
\begin{bmatrix}
    u(\lambda_w) \\ v(\phi_w) \\ 1
\end{bmatrix} = 
\begin{bmatrix}
    \frac{W}{2\pi} & 0 & \frac{W}{2} \\
    0 & \frac{-H}{\pi} & \frac{H}{2} \\
    0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
    \lambda_w \\ \phi_w \\ 1
\end{bmatrix} = 
S^{-1} \begin{bmatrix}
    \lambda_w \\ \phi_w \\ 1
\end{bmatrix}
$$



\subsection{Rotating sphere to camera perspective}
Applying rotation matrices on the world coordinates to obtain the camera view, we have:
\begin{align*}
\begin{bmatrix}
\lambda_c \\ \phi_c \\ 1 
\end{bmatrix} &= 
P^{-1} R_{yaw}(30^\circ) R_{pitch}(10^\circ) R_{roll}(25^\circ) P
\begin{bmatrix}
    \lambda_w \\ \phi_w \\ 1
\end{bmatrix} \\
&= R\begin{bmatrix}
    \lambda_w \\ \phi_w \\ 1
\end{bmatrix}
\end{align*}

Where $R$ is the camera rotation matrix and $P$ is the matrix transforming polar coordinates to cartesian coordinates. 
We let $x$ be the horizonal aspect of the view, $y$ be the vertical, and $z$ be the depth. 
According to the rotations conventions, we have 
\begin{align*}
    R_{yaw}(30^\circ) &= \begin{bmatrix}
        \cos 30^\circ & 0 & -\sin 30^\circ \\
        0 & 1 & 0 \\
        \sin 30^\circ & 0 & cos 30^\circ
    \end{bmatrix} && \text{ y axis} \\
    R_{pitch}(10^\circ) &= \begin{bmatrix}
        1 & 0 & 0 \\
        0 & \cos 10^\circ & -\sin 10^\circ \\
        0 & \sin 10^\circ & \cos 10^\circ
    \end{bmatrix} && \text{ x axis} \\ 
    R_{roll}(25^\circ) &= \begin{bmatrix}
        \cos 25^\circ & -\sin 25^\circ & 0 \\
        \sin 25^\circ & \cos 25^\circ & 0 \\
        0 & 0 & 1
    \end{bmatrix} && \text{ z axis}
\end{align*}

\subsection{Sampling from Camera coordinates}
We sample $(u_c, v_c) \in [0, W) \times [0, H)$ with 
$\lambda_c(u_c) = \frac{\pi}{2W}u_c - \frac{\pi}{4}$, $\phi_c(v_c) = \frac{\pi}{2H}v_c - \frac{\pi}{4}$. 
This way, the range of sampled angles for $\lambda_c, \phi_c \in (-\frac{\pi}{4}, \frac{\pi}{4})$, which corresponds to a $90^\circ$ viewing angle. 

\subsection{Putting it together}. 
Therefore, we can construct the perspective view image (new) from the original image (old) by composing transformations of each step. 
Giving us 
\[
New(u_c, v_c) = Old(
S^{-1}
R^{-1}
\begin{bmatrix}
    \frac{\pi}{2W}u_c - \frac{\pi}{4} \\ 
    \frac{\pi}{2H}v_c - \frac{\pi}{4} \\ 
    1
\end{bmatrix}
)
\] 

\section{Part 2}
Starting from any orientation, you can yaw $90$,$ -90$, and $180$ to obtain $3$ faces. And pitch up $90$ and down $90$ to obtain the other $2$. 
Therefore, let $R$ be as defined in part $1$. Then the question is to find $r, p, y$ such that 
$R(r, p, y) = R_\Delta R(25, 10, 30)$
where $R_\Delta \in \{R_{yaw}(90), R_{yaw}(-90), R_{yaw}(180), R_{pitch}(90), R_{pitch}(-90)\}$
\section{Part 3: Sampling Jacobian and solid-angle element} 
\paragraph{Solid-angle element on the unit sphere.}
The catesian position of unit sphere points are parametrized by 
\[
\bm{p}(\lambda,\phi)=
\begin{bmatrix}
\cos\phi\cos\lambda\\[2pt]
\sin\phi\\[2pt]
\cos\phi\sin\lambda
\end{bmatrix}.
\] longitude $\lambda \in [-\pi,\pi)$ and latitude
$\phi \in [-\tfrac{\pi}{2},\tfrac{\pi}{2}]$ via
Then
\[
\partial_\lambda \bm{p}=
\begin{bmatrix}
-\cos\phi\sin\lambda\\[2pt]
0\\[2pt]
\cos\phi\cos\lambda
\end{bmatrix},\qquad
\partial_\phi \bm{p}=
\begin{bmatrix}
-\sin\phi\cos\lambda\\[2pt]
\cos\phi\\[2pt]
-\sin\phi\sin\lambda
\end{bmatrix}.
\]
The differential area (and hence solid angle on the unit sphere) is
\[
d\Omega \;=\; \|\partial_\lambda \bm{p}\times \partial_\phi \bm{p}\|\; d\lambda\, d\phi
\;=\; \cos\phi \; d\lambda\, d\phi.
\]
Thus the solid-angle element maps from ERM angles as
\[
\boxed{\,d\Omega=\cos\phi\; d\lambda\, d\phi\, }.
\]

\paragraph{From image pixels $(u,v)$ to solid angle.}
With the equirectangular mapping
\[
\lambda(u)=2\pi \frac{u}{W}-\pi,\qquad
\phi(v)=\frac{\pi}{2}-\pi\frac{v}{H},
\]
the Jacobian from $(u,v)$ to $(\lambda,\phi)$ is constant:
\[
\frac{\partial(\lambda,\phi)}{\partial(u,v)}
=
\begin{vmatrix}
\frac{\partial \lambda}{\partial u} & \frac{\partial \lambda}{\partial v}\\[2pt]
\frac{\partial \phi}{\partial u} & \frac{\partial \phi}{\partial v}
\end{vmatrix}
=
\begin{vmatrix}
\frac{2\pi}{W} & 0\\[2pt]
0 & -\frac{\pi}{H}
\end{vmatrix}
= -\,\frac{2\pi^2}{WH}.
\]
Taking the absolute value for area,
\[
d\lambda\, d\phi=\frac{2\pi^2}{WH}\, du\, dv,
\]
so a pixel area $du\,dv$ subtends solid angle
\[
\boxed{\, d\Omega \;=\; \cos\phi(v)\;\frac{2\pi^2}{WH}\; du\, dv\, }.
\]
Equivalently, the per-pixel solid angle is
\[
\boxed{\, \Delta\Omega(u,v) \;\approx\; \cos\!\big(\phi(v)\big)\;\frac{2\pi^2}{WH}\, }.
\]
Hence each ERM texel covers \emph{larger} solid angle near the equator ($\phi\approx 0$) and \emph{shrinks} to zero near the poles ($|\phi|\to \tfrac{\pi}{2}$).

\paragraph{Implications for importance sampling.}
Uniformly picking ERM pixels (uniform in $u,v$) is \emph{not} uniform over directions:
the induced PDF on latitude is proportional to $\cos\phi$. To sample directions
uniformly on the sphere, draw
\[
\lambda \sim \mathrm{Unif}[-\pi,\pi),\qquad
\phi \;\text{ with PDF }\; f_\phi(\phi)=\tfrac{1}{2}\cos\phi\ \Rightarrow\
\phi=\arcsin(2\xi-1),\ \xi\sim\mathrm{Unif}[0,1].
\]
For environment-map \emph{importance sampling}, weight texels by
$l(u,v)\cos\phi(v)$ (radiance/luminance times $\cos\phi$) when building the sampling distribution, so that selection probability is proportional to contribution per unit solid angle.

\paragraph{Implications for antialiasing near the poles.}
Because horizontal arc length on the sphere scales as $\cos\phi$ for a given $d\lambda$,
ERM \emph{oversamples} near the poles and \emph{undersamples} near the equator in terms of solid angle per texel. When resampling an ERM into a perspective view, the reconstruction footprint in texture space should therefore be \emph{anisotropic}, using a larger longitudinal filter support at high latitudes:
\[
\text{effective longitudinal footprint} \;\propto\; \frac{1}{\cos\phi}.
\]
Practically: use MIP/anisotropic filtering with an LOD bias that increases toward the poles (in the $u$/$\lambda$ direction), or average $\sim 1/\cos\phi$ more ERM texels horizontally at high $|\phi|$. This preserves energy (solid angle) and reduces aliasing/over-blur artifacts that otherwise appear when extracting views near the poles.

\end{document}